{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_notebook_binary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNW6uStgdGnDCBUxdynpkNz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mYBKqPLvE4q"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os\n",
        "\n",
        "from matplotlib import rcParams\n",
        "import plotly.graph_objs as go\n",
        "import plotly.plotly as py\n",
        "from plotly.graph_objs import *\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import category_encoders as ce\n",
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import neural_network, naive_bayes, neighbors, svm, ensemble, tree, metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "%matplotlib inline \n",
        "%pylab inline \n",
        "\n",
        "%matplotlib inline \n",
        "%pylab inline \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Internship VITO/Data/Databuild Louis output_V3_age.xlsx'\n",
        "import pandas as pd\n",
        "df1 = pd.read_excel(path)"
      ],
      "metadata": {
        "id": "nDOH0nhLIeNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the values where Type2 variable is equal to resource, because in those rows an article is never used \n",
        "df1.drop(df1.index[df1['Type2'] == 'Resource'], inplace = True)\n",
        "df1"
      ],
      "metadata": {
        "id": "WFAMhmGkIhq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove duplicate rows \n",
        "df1 = df1.drop_duplicates()\n",
        "len(df1)  #Should be 233639"
      ],
      "metadata": {
        "id": "eBh4lWu0IkJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create variable counts which counts number of type a specific device has already been brought in\n",
        "df1['Counts'] = df1.groupby(['Serial No_', 'Order Date'])['No_'].transform('count')\n",
        "\n",
        "#Round up Counts variable\n",
        "df1['Counts'] = round(df1['Counts'])"
      ],
      "metadata": {
        "id": "CUprWP8qIoa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Imputation\n",
        "df1['Purchase Price'] = df1.groupby(['Type'], sort=False)['Purchase Price'].apply(lambda x: x.fillna(x.mean()))\n",
        "df1['Years of Warranty'] = df1.groupby(['Type'], sort=False)['Years of Warranty'].apply(lambda x: x.fillna(x.mean()))\n",
        "df1['Counts'] = df1.groupby(['Type'], sort=False)['Counts'].apply(lambda x: x.fillna(x.mean()))\n",
        "df1['Service Type'] = df1.groupby(['Type'], sort=False)['Service Type'].apply(lambda x: x.fillna(x.mode()))\n",
        "df1['Vendor Item No_'] = df1.groupby(['Type'], sort=False)['Vendor Item No_'].apply(lambda x: x.fillna(x.mode()))\n",
        "df1['Warranty'] = df1.groupby(['Type'], sort=False)['Warranty'].apply(lambda x: x.fillna(x.mode()))\n",
        "df1['Repair Status Code'] = df1.groupby(['Type'], sort=False)['Warranty'].apply(lambda x: x.fillna(x.mode()))"
      ],
      "metadata": {
        "id": "O74FsEv0IpEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop 39 rows with Colorcade NaN\n",
        "df1 = df1.dropna(subset=[\"ColorCode\"])\n",
        "df1"
      ],
      "metadata": {
        "id": "eijNVoQxIsU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove columns that are not used\n",
        "df2 = df1.drop(['No_', 'Order Date', 'T4', 'Source Receipt', 'Warranty Ending Date (Parts)', 'Warranty Ending Date (Labor)', 'Vendor No_', 'Repair Status Code', 'Production Date', 'Date_Today', 'Warranty Starting Date (Labor)', 'Warranty Ending Date (Labor)2', 'Type2', 'ColorcodeDescription', 'Total Amount', 'No_2', 'Amount Including VAT', 'Vendor Item No_', 'Description', 'Probleem Omschrijving', 'Oplossing Omschrijving', 'Diagnose Omschrijving',], axis = 1)\n",
        "df2"
      ],
      "metadata": {
        "id": "QdgRSYu7IvL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.drop(['No_', 'Order Date', 'T4', 'Source Receipt', 'Warranty Ending Date (Parts)', 'Warranty Ending Date (Labor)', 'Vendor No_', 'Repair Status Code', 'Production Date', 'Date_Today', 'Warranty Starting Date (Labor)', 'Warranty Ending Date (Labor)2', 'Type2', 'ColorcodeDescription', 'Total Amount', 'No_2', 'Amount Including VAT', 'Vendor Item No_', 'Description', 'Probleem Omschrijving', 'Oplossing Omschrijving', 'Diagnose Omschrijving',], axis = 1)\n",
        "df2"
      ],
      "metadata": {
        "id": "OS-NMlYpIvS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Probleem code'] = df2['Probleem code'].replace('NO START','POWER')    \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('AUDIO CRACKING NOISE','AUDIO')         \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE VERT BLOCK','PICTURE')    \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('CHARGING PROBLEM','POWER')    \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE PIXEL DEF','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE LEAKAGE','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE DARK SPOT','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE DARK SPOT','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('INT CONNECTION','CONNECTION')\n",
        "df2['Probleem code'] = df2['Probleem code'].replace('NO START STANDBY','POWER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('DARK SPOT','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('IR PROBLEM','OTHER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MEMORY','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('AMBILIGHT','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('KEYBOARD PROBLEM','OTHER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('FUNCTION PROBLEM','OTHER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('ELECTRICAL PROBLEM','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('SOFTWARE','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('READING PROBLEMS','OTHER')\n",
        "df2['Probleem code'] = df2['Probleem code'].replace('BOOT/LOOP','OTHER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MEMORY','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('SMELL','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PANEL DAMAGE','OTHER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('LIGHT LEAKAGE','OTHER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('INSTALATION','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('DOA DAMAGED','OTHER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('BAD OPERATION IN/OUT','OTHER') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('GEEN','OTHER') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('OTE','OTHER') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE BAD','PICTURE')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('POWER NO START','POWER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE NO','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('INT POWER ON/OFF','POWER')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('CONNECTION PROBLEM','CONNECTION')   \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE PIXELLINE','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE LINE/PIXELS','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('CONNECTION WIRELESS','CONNECTION') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('AUDIO DEFORMED','AUDIO') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('AUDIO NO','AUDIO') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('INT PICTURE','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('CONNECTION WIRED','CONNECTION') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('NO POWER','POWER') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('INT AUDIO','AUDIO') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MECHANICAL PROBLEM','MECHANICAL') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MECHANICAL ALIGNMENT','MECHANICAL') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MECHANICAL NOISE','MECHANICAL') \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE FREEZE','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE BLUE','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE RETENTION','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('POWER PROBLEM','POWER')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MECHNICAL BLOCKED','MECHANICAL')    \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE PROBLEM','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE PROBLEM LED','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('PICTURE HORI BLOCK','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('AUDIO PROBLEM','AUDIO')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('NO VIDEO','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('GEEN BEELD','PICTURE')     \n",
        "df2['Probleem code'] = df2['Probleem code'].replace('MECHANICAL BLOCKED','MECHANICAL') \n",
        "\n",
        "\n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('THOMSON','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('TCL','OTHER') \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('SALORA','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('HAIER','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('B&O','OTHER') \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('HISENSE','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('GRUNDIG','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('SONY','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('ROWA','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('OK','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('INUVIK','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('TOSHIBA','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('SCHNEIDER','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('SHARP','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('KUPPERSBUS','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('DIVERS','OTHER')     \n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('SILVERCRES','OTHER')\n",
        "\n",
        "\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([1050.0 ,775.0, 200.0,                   \n",
        "1000.0, 350.0, 500.0, 760.0, 585.00, 100.00, 170.00, 150.00, 700.0, 550.0, 750.0, 450.0],\n",
        "['SSB / Main','LCD Display Panel', 'Cabinet/ Backcover', 'Power Supply Unit/IPB', 'Cable Intern', 'Remote Control', \n",
        " 'LED Array', 'I/O Board / Wifimod', 'Material Divers', 'Swap Complete Device', 'Stand',  'LVDS Cable', \n",
        " 'Speakers / Audioboards', 'LCD Parts : t-con/invertors','IR Print Ontvanger'])\n",
        "\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([160.0],'Part')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([400.0],'Keyboard, Knobframe')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([3900.0],'PCB/MAIN')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([360.0],'Connector')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([180.0],'COOLING & FANS')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([575.0],'Ambilights modules')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([1025.0 ],'Modifiaction SSB / Main')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([25100.0],'Cover')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([801.0],'CD/DVD Loader')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([11030.0],'PCB Main')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([650.0],'PDP : plasma panel')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([950.0],'Modification PSU / IPB')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([600.0],'PDP parts : X - Y sus logic boards van PDP')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([12010.0],'Back tub')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([300.0],'Sensor')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([3310.0],'CONNECTOR')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([3300.0],'FANS')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([23010.0],'Diode')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50161.0],'Wifi/Bluetooth')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50051.0],'LVDS')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50116.0],'Housing-Rear')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50160.0],'inveter PVB')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50204.0],'LCD Module')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50155.0],'IR Sensor Module')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50202.0],'T-con')\n",
        "df2['ColorCode']= df2['ColorCode'].replace([50053.0],'One-connect Cable')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50005.0],'Stand')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50162.0],'Ambilight Module')\n",
        "df2['ColorCode']= df2['ColorCode'].replace([50152.0],'Input Board')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50112.0],'Housing Front')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50256.0],'Motor')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50153.0],'Keyboard')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50052.0],'Flat Cable')     \n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50113.0],'Housing-Top')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50109.0],'Feet Legs')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50111.0],'Housing-Bottom')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50100.0],'Housing')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50006.0],'Stand Connecting Piece')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50265.0],'Gasket')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50102.0],'Rear Cover')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50252.0],'Fan')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50050.0],'Cables')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50352.0],'Screws')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50159.0],'AC-Adaptor')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50101.0],'Bracket Wire')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50354.0],'Tuner')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50151.0 ],'Mainboard')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([0.0],'OLD')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50203.0 ],'LCD/LED panel-TV')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50158.0 ],'Power Supply')\n",
        "df2['ColorCode']= df2['ColorCode'].replace([50056.0 ],'Internal Cable')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50359.0],'Swap')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50157.0],'One-Connect Box')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50201.0],'Backlight')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50401.0],'Speaker')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace([50004.0],'Remote Control')"
      ],
      "metadata": {
        "id": "mRPz2YsbJAL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['ColorCode'] = df2['ColorCode'].replace(['Stand'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['LVDS Cable'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Speaker / Audioboards'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['IR Print Ontvanger'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Part'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Keyboard, Knobframe'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['LCD Parts : t-con/invertors'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Connector'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['COOLING & FANS'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Ambilights modules'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Speaker / Audioboards'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['PDP parts : X - Y sus logic boards van PDP'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Back tub'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Sensor'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['FANS'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Cover'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['CD/DVD Loader'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['PDP : plasma panel'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Modification PSU / IPB'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Speakers / Audioboards'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Diode'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['AC-Adaptor'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Tuner'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Screws '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Cables '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Fan'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Rear Cover'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Gasket'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Stand Connecting Piece'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Bottom  '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Bracket Wire'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Top '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Keyboard'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Flat Cable'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing Front'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Ambilight Module'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['One-connect Cable'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['T-con'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['IR Sensor Module'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['AC-Adaptor'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Tuner'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Fan'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Rear Cover'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Gasket'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Stand Connecting Piece'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Bottom  '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Bracket Wire'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Top '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Keyboard'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Flat Cable'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing Front'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Input Board'],['I/O Board / Wifimod'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Ambilight Module'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['One-connect Cable'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['T-con'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['IR Sensor Module'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Screws'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Cables'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Feet Legs'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['LCD Module'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['inveter PVB '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Speaker'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Rear'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['LVDS'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Backlight'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['One-Connect Box'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Swap'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['inveter PVB '],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Material Divers'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['LED Array'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Swap Complete Device'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Power Supply'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Internal Cable'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Wifi/Bluetooth'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['inveter PVB'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Top'],['Other'])\n",
        "df2['ColorCode'] = df2['ColorCode'].replace(['Housing-Bottom'],['Other'])"
      ],
      "metadata": {
        "id": "f-Nq0m95JIvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['ColorCode'] = df2['ColorCode'].replace('PCB Main','PCB/MAIN')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace('CONNECTOR','Connector')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace('SSB / Main','Mainboard')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace('LCD Display Panel','LCD/LED panel-TV')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace('Modifiaction SSB / Main','Mainboard')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace('PCB/MAIN','Mainboard')\n",
        "df2['ColorCode'] = df2['ColorCode'].replace('Connector','Other')\n",
        "\n",
        "df2['Service Type'] = df2['Service Type'].replace('TECHOME','HOMESERVICE')\n",
        "df2['Service Type'] = df2['Service Type'].replace('REPAIR_NAR','REPAIR')\n",
        "df2['Service Type'] = df2['Service Type'].replace('REPAIR5J','REPAIR')\n",
        "df2['Service Type'] = df2['Service Type'].replace('OMRUIL','SWAP')\n",
        "df2['Service Type'] = df2['Service Type'].replace('TECSWAP','SWAP')\n",
        "df2['Service Type'] = df2['Service Type'].replace('ADSWAP','SWAP')\n",
        "df2['Service Type'] = df2['Service Type'].replace('LOGSWAP','SWAP')\n",
        "df2['Service Type'] = df2['Service Type'].replace('BISWAP','SWAP')\n",
        "df2['Service Type'] = df2['Service Type'].replace('HOMESERVICE','HOMESERVI')\n",
        "df2['Service Type'] = df2['Service Type'].replace('NAAR3','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('INSTALL','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('RECALL','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('SAMCI','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('PREMIUM','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('TRANSPORT','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('QUICKCHECK','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('GHANZINSTA','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('RET_TEKA','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('DOA','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('LOGRETURN','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('OUTWAR','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('TECPICKUP','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('C2SEB','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('LOGPICKUP','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('CENTRALREP','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('EXPERTISE','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('PICKUP','OTHER2')\n",
        "df2['Service Type'] = df2['Service Type'].replace('TECRETURN','OTHER2')"
      ],
      "metadata": {
        "id": "dRBeaFXrJa1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond1 = df2.Type.str.contains('OLED')\n",
        "cond2 = df2.Type.str.contains('QE')\n",
        "cond3 = df2.Type.str.contains('UE')\n",
        "cond4 = df2.Type.str.contains('EF')\n",
        "cond5 = df2.Type.str.contains('UH')\n",
        "cond6 = df2.Type.str.contains('LB')\n",
        "cond7 = df2.Type.str.contains('UJ')\n",
        "cond8 = df2.Type.str.contains('UF')\n",
        "cond9 = df2.Type.str.contains('EG')\n",
        "cond10 = df2.Type.str.contains('LF')\n",
        "cond11 = df2.Type.str.contains('LJ')\n",
        "cond12 = df2.Type.str.contains('UK')\n",
        "cond13 = df2.Type.str.contains('SJ')\n",
        "\n",
        "df2['Technology'] = np.where(cond1 & cond9, 'OLED', np.where(cond2, 'QLED', np.where(cond3, 'LCD-LED', \n",
        "np.where(cond4, 'OLED', np.where(cond5, 'LCD-LED', np.where(cond6, 'LCD-LED', np.where(cond7, 'LCD-LED', \n",
        "np.where(cond8, 'LCD-LED', np.where(cond9, 'OLED', np.where(cond10, 'LCD-LED', np.where(cond11, 'LCD-LED', \n",
        "np.where(cond12, 'LCD-LED', np.where(cond13, 'LCD-LED','not found')))))))))))))"
      ],
      "metadata": {
        "id": "YaudjizcJgeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond1 = df2.Type.str.contains('QE49')\n",
        "cond2 = df2.Type.str.contains('QE50')\n",
        "cond3 = df2.Type.str.contains('QE55')\n",
        "cond4 = df2.Type.str.contains('QE58')\n",
        "cond5 = df2.Type.str.contains('QE65')\n",
        "cond6 = df2.Type.str.contains('QE75')\n",
        "cond7 = df2.Type.str.contains('QE82')\n",
        "cond8 = df2.Type.str.contains('QE85')\n",
        "cond9 = df2.Type.str.contains('UE22')\n",
        "cond10 = df2.Type.str.contains('UE24')\n",
        "cond11 = df2.Type.str.contains('UE32')\n",
        "cond12 = df2.Type.str.contains('UE39')\n",
        "cond13 = df2.Type.str.contains('UE40')\n",
        "cond14 = df2.Type.str.contains('UE43')\n",
        "cond15 = df2.Type.str.contains('UE46')\n",
        "cond16 = df2.Type.str.contains('UE48')\n",
        "cond17 = df2.Type.str.contains('UE49')\n",
        "cond18 = df2.Type.str.contains('UE50')\n",
        "cond19 = df2.Type.str.contains('UE55')\n",
        "cond20 = df2.Type.str.contains('UE58')\n",
        "cond21 = df2.Type.str.contains('UE60')\n",
        "cond22 = df2.Type.str.contains('UE65')\n",
        "cond23 = df2.Type.str.contains('UE70')\n",
        "cond24 = df2.Type.str.contains('UE75')\n",
        "cond25 = df2.Type.str.contains('UE78')\n",
        "cond26 = df2.Type.str.contains('UE82')\n",
        "cond28 = df2.Type.str.contains('32LJ')\n",
        "cond29 = df2.Type.str.contains('32LK')\n",
        "cond30 = df2.Type.str.contains('32PF')\n",
        "cond31 = df2.Type.str.contains('32PH')\n",
        "cond33 = df2.Type.str.contains('43LJ')\n",
        "cond34 = df2.Type.str.contains('43PF')\n",
        "cond35 = df2.Type.str.contains('43PU')\n",
        "cond36 = df2.Type.str.contains('43UH')\n",
        "cond37 = df2.Type.str.contains('43UJ')\n",
        "cond38 = df2.Type.str.contains('43UK')\n",
        "cond39 = df2.Type.str.contains('43UM')\n",
        "cond40 = df2.Type.str.contains('49LB')\n",
        "cond41 = df2.Type.str.contains('49NAN')\n",
        "cond42 = df2.Type.str.contains('49PU')\n",
        "cond43 = df2.Type.str.contains('49SJ')\n",
        "cond44 = df2.Type.str.contains('49SK')\n",
        "cond45 = df2.Type.str.contains('55EG')\n",
        "cond46 = df2.Type.str.contains('55POS')\n",
        "cond47 = df2.Type.str.contains('55PUS')\n",
        "cond48 = df2.Type.str.contains('OLED48')\n",
        "cond49 = df2.Type.str.contains('OLED55')\n",
        "cond50 = df2.Type.str.contains('OLED65')\n",
        "cond51 = df2.Type.str.contains('OLED77')\n",
        "cond52 = df2.Type.str.contains('QE32')\n",
        "cond53 = df2.Type.str.contains('QE43')\n",
        "\n",
        "df2['Type_short'] = np.where(cond1, 'QE49', np.where(cond2, 'QE50', np.where(cond3, 'QE55', \n",
        "np.where(cond4, 'QE58', np.where(cond5, 'QE65', np.where(cond6, 'QE75', np.where(cond7, 'QE82', \n",
        "np.where(cond8, 'QE85', np.where(cond9, 'UE22', np.where(cond10, 'UE24', np.where(cond11, 'UE32', \n",
        "np.where(cond12, 'UE39', np.where(cond13, 'UE40' , np.where(cond14, 'UE43', np.where(cond15, 'UE46', np.where(cond16, 'UE48',\n",
        "np.where(cond17, 'UE49',np.where(cond18, 'UE50', np.where(cond19, 'UE55', np.where(cond20, 'UE58', np.where(cond21, 'UE60', \n",
        "np.where(cond22, 'UE65', np.where(cond23, 'UE70', np.where(cond24, 'UE75', np.where(cond25, 'UE78', np.where(cond26, 'UE82',\n",
        "np.where(cond28, '32LJ', np.where(cond29, '32LK',   np.where(cond30, '32PF',  np.where(cond31, '32PH', \n",
        "np.where(cond33, '43LJ',  np.where(cond34, '43PF', np.where(cond35, '43PU', np.where(cond36, '43PF', np.where(cond37, '43UJ', \n",
        "np.where(cond38, '43UK', np.where(cond39, '43UM', np.where(cond40, '49LB', \n",
        "np.where(cond41, '49NAN', np.where(cond42, '43PU', np.where(cond43, '43SJ', np.where(cond44, '49SK', np.where(cond45, '55EG', \n",
        "np.where(cond46, '55POS',  np.where(cond47, '55PUS',  np.where(cond48, 'OLED48', np.where(cond49, 'OLED55',\n",
        "np.where(cond50, 'OLED65', np.where(cond51, 'OLED77', np.where(cond52, '55PUS',\n",
        "np.where(cond52, 'QE32','other')))))))))))))))))))))))))))))))))))))))))))))))))))\n",
        "                                                              "
      ],
      "metadata": {
        "id": "hzRr1CfaJlGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove ColorCodes with old values (old system of Servilux)\n",
        "df2 = df2.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n",
        "df2.drop(df2[df2['ColorCode'] == \"OLD\"].index, inplace=True)\n",
        "df2"
      ],
      "metadata": {
        "id": "rb3driaFJmgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####"
      ],
      "metadata": {
        "id": "dbVJ73ntJy8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Repclacement of Brand\n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('XXX','Brand A')\n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('XXX','Brand B')\n",
        "df2['Manufacturer Code'] = df2['Manufacturer Code'].replace('XXX','Brand C')\n",
        "df2.drop(df2[df2['Manufacturer Code'] == \"OTHER\"].index, inplace=True)"
      ],
      "metadata": {
        "id": "JsallDEbJzjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#factorize the output variable (between 0 & 7)\n",
        "factor = pd.factorize(df2['ColorCode'])\n",
        "df2.ColorCode = factor[0]\n",
        "definitions = factor[1]\n",
        "print(df2.ColorCode.head())\n",
        "print(definitions)"
      ],
      "metadata": {
        "id": "V97UvAONJzsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)"
      ],
      "metadata": {
        "id": "0vZRFKy_Ktde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REMOVE SOME LAST OUTLIERS \n",
        "df2.drop(df2.loc[df2['Age_BI']> 30].index, inplace=True)\n",
        "df2.hist()\n",
        "df2.drop(df2.loc[df2['Age_BI'] < 0].index, inplace=True)\n",
        "df2.hist()"
      ],
      "metadata": {
        "id": "8QT5bWZsKydb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RQ7cm2inLI_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create two sets one with rows where Count = 1 & one with Counts > 1\n",
        "df_count_1 = df2.drop(df2[df2.Counts > 1].index)\n",
        "df_count_1_more = df2.drop(df2[df2.Counts == 1].index)"
      ],
      "metadata": {
        "id": "svApFt2jK31z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 0\n",
        "df_CC_0 = df_count_1_more\n",
        "to_drop = []\n",
        "for idx, row in df_CC_0.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 0:\n",
        "\n",
        "        rows_with_same_snr = df_CC_0.index[df_CC_0[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "HokY7GEVLJby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop = [item for sublist in to_drop for item in sublist]\n",
        "new_df_CC_0 = df_CC_0.drop(to_drop, inplace = False )\n",
        "frames_0 = [df_count_1, new_df_CC_0]\n",
        "df_0_0 = pd.concat(frames_0)"
      ],
      "metadata": {
        "id": "glifr8lMLSmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 1\n",
        "\n",
        "df_CC_1 = df_count_1_more\n",
        "to_drop_1 = []\n",
        "for idx, row in df_CC_1.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 1:\n",
        "\n",
        "        rows_with_same_snr = df_CC_1.index[df_CC_1[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_1.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "mgFInqhZLY_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_1 = [item for sublist in to_drop_1 for item in sublist]\n",
        "new_df_CC_1 = df_CC_1.drop(to_drop_1, inplace = False )\n",
        "frames_1 = [df_count_1, new_df_CC_1]\n",
        "df_0_1 = pd.concat(frames_1)"
      ],
      "metadata": {
        "id": "JflHbhFNMFTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 2\n",
        "df_CC_2 = df_count_1_more\n",
        "to_drop_2 = []\n",
        "for idx, row in df_CC_2.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 2:\n",
        "\n",
        "        rows_with_same_snr = df_CC_2.index[df_CC_2[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_2.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "EpU8JeX2MFum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_2 = [item for sublist in to_drop_2 for item in sublist]\n",
        "new_df_CC_2 = df_CC_2.drop(to_drop_2, inplace = False )\n",
        "frames_2 = [df_count_1, new_df_CC_2]\n",
        "df_0_2 = pd.concat(frames_2)"
      ],
      "metadata": {
        "id": "IYs2q62bMGBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 3\n",
        "\n",
        "df_CC_3 = df_count_1_more\n",
        "to_drop_3 = []\n",
        "for idx, row in df_CC_1.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 3:\n",
        "\n",
        "        rows_with_same_snr = df_CC_3.index[df_CC_3[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_3.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "3V5GrLGoMGDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_3= [item for sublist in to_drop_3 for item in sublist]\n",
        "new_df_CC_3 = df_CC_3.drop(to_drop_3, inplace = False )\n",
        "frames_3 = [df_count_1, new_df_CC_3]\n",
        "df_0_3 = pd.concat(frames_3)"
      ],
      "metadata": {
        "id": "LCmFivNOMGGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 4\n",
        "\n",
        "df_CC_4 = df_count_1_more\n",
        "to_drop_4 = []\n",
        "for idx, row in df_CC_4.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 4:\n",
        "\n",
        "        rows_with_same_snr = df_CC_4.index[df_CC_4[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_4.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "MqaImHysMp_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_4= [item for sublist in to_drop_4 for item in sublist]\n",
        "new_df_CC_4 = df_CC_4.drop(to_drop_4, inplace = False )\n",
        "frames_4 = [df_count_1, new_df_CC_4]\n",
        "df_0_4 = pd.concat(frames_4)"
      ],
      "metadata": {
        "id": "sfqHc3dbMqCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 5\n",
        "df_CC_5 = df_count_1_more\n",
        "to_drop_5 = []\n",
        "for idx, row in df_CC_5.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 5:\n",
        "\n",
        "        rows_with_same_snr = df_CC_5.index[df_CC_5[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_5.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "BLCH7rjWMqEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_5= [item for sublist in to_drop_5 for item in sublist]\n",
        "new_df_CC_5 = df_CC_5.drop(to_drop_5, inplace = False )\n",
        "frames_5 = [df_count_1, new_df_CC_5]\n",
        "df_0_5 = pd.concat(frames_5)"
      ],
      "metadata": {
        "id": "faHj9TZqMqGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 6\n",
        "\n",
        "df_CC_6 = df_count_1_more\n",
        "to_drop_6 = []\n",
        "for idx, row in df_CC_6.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 6:\n",
        "\n",
        "        rows_with_same_snr = df_CC_6.index[df_CC_6[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_6.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "OMzIQ4D4NEhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_6= [item for sublist in to_drop_6 for item in sublist]\n",
        "new_df_CC_6 = df_CC_6.drop(to_drop_6, inplace = False )\n",
        "frames_6 = [df_count_1, new_df_CC_6]\n",
        "df_0_6 = pd.concat(frames_6)s"
      ],
      "metadata": {
        "id": "_bt8y-aENEkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For ColorCode = 7\n",
        "\n",
        "df_CC_7 = df_count_1_more\n",
        "to_drop_7 = []\n",
        "for idx, row in df_CC_7.iterrows():\n",
        "\n",
        "    if row[\"ColorCode\"] == 7:\n",
        "\n",
        "        rows_with_same_snr = df_CC_7.index[df_CC_7[\"Serial No_\"] == row[\"Serial No_\"]].tolist()\n",
        "        \n",
        "        print(rows_with_same_snr)\n",
        "        \n",
        "        rows_with_same_snr.remove(idx)\n",
        "        \n",
        "        to_drop_7.append(rows_with_same_snr)"
      ],
      "metadata": {
        "id": "sWtBkx0uNEmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop_7= [item for sublist in to_drop_7 for item in sublist]\n",
        "new_df_CC_7 = df_CC_7.drop(to_drop_7, inplace = False )\n",
        "frames_7 = [df_count_1, new_df_CC_7]\n",
        "df_0_7 = pd.concat(frames_7)"
      ],
      "metadata": {
        "id": "HQP8JusxMqJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a subset for the training => ColorCode = 0\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0 = df_0_0.sample(frac = 1)  \n",
        "print(df_0) \n",
        "\n",
        "#Create a subset for the training => ColorCode = 1\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_1 = df_0_1.sample(frac = 1)  \n",
        "print(df_0_1) \n",
        "\n",
        "#Create a subset for the training => ColorCode = 2\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_2 = df_0_2.sample(frac = 1)  \n",
        "print(df_0_2) \n",
        "\n",
        "#Create a subset for the training => ColorCode = 3\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_3 = df_0_3.sample(frac = 1)  \n",
        "print(df_0_3) \n",
        "\n",
        "#Create a subset for the training => ColorCode = 4\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_4 = df_0_4.sample(frac = 1)  \n",
        "print(df_0_4) \n",
        "\n",
        "#Create a subset for the training => ColorCode = 5\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_5 = df_0_5.sample(frac = 1)  \n",
        "\n",
        "print(df_0_5) #Create a subset for the training => ColorCode = 6\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_6 = df_0_6.sample(frac = 1)  \n",
        "print(df_0_6) \n",
        "\n",
        "#Create a subset for the training => ColorCode = 7\n",
        "numpy.random.seed(436862)                                       \n",
        "df_0_7 = df_0_7.sample(frac = 1)  \n",
        "print(df_0_7) "
      ],
      "metadata": {
        "id": "MwWRvc3ANpDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Division of the dataframe in numerical and categorical variables + creation of binary y-value. \n",
        "\n",
        "x_0_n_0_f = df_0[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_0_c_0_f = df_0[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]\n",
        "y_0 = df_0['ColorCode']\n",
        "df_0['y_0_0'] = np.where(df_0[\"ColorCode\"] == 0, 1, 0)\n",
        "y_0_0 = df_0['y_0_0']\n",
        "\n",
        "x_1_n_0_f = df_0_1[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_1_c_0_f = df_0_1[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]\n",
        "y_0 = df_0_1['ColorCode']\n",
        "df_0_1['y_0_1'] = np.where(y_0 == 1, 1, 0)\n",
        "y_0_1 = df_0_1['y_0_1']\n",
        "\n",
        "x_2_n_0_f = df_0_2[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_2_c_0_f = df_0_2[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]                \n",
        "y_2 = df_0_2['ColorCode']\n",
        "df_0_2['y_0_2'] = np.where(y_2 == 2, 1, 0)\n",
        "y_0_2 = df_0_2['y_0_2']\n",
        "\n",
        "x_3_n_0_f = df_0_3[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_3_c_0_f = df_0_3[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]             \n",
        "y_3 = df_0_3['ColorCode']\n",
        "df_0_3['y_0_3'] = np.where(y_3 == 3, 1, 0)\n",
        "y_0_3 = df_0_3['y_0_3']\n",
        "\n",
        "x_4_n_0_f = df_0_4[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_4_c_0_f = df_0_4[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]\n",
        "y_4 = df_0_4['ColorCode']\n",
        "df_0_4['y_0_4'] = np.where(y_4 == 4, 1, 0)\n",
        "y_0_4 = df_0_4['y_0_4']\n",
        "\n",
        "x_5_n_0_f = df_0_5[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_5_c_0_f = df_0_5[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]               \n",
        "y_5 = df_0_5['ColorCode']\n",
        "df_0_5['y_0_5'] = np.where(y_5 == 5, 1, 0)\n",
        "y_0_5 = df_0_5['y_0_5']\n",
        "\n",
        "x_6_n_0_f = df_0_6[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_6_c_0_f = df_0_6[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]\n",
        "y_6 = df_0_6['ColorCode']\n",
        "df_0_6['y_0_6'] = np.where(y_6 == 6, 1, 0)\n",
        "y_0_6 = df_0_6['y_0_6']\n",
        "\n",
        "x_7_n_0_f = df_0_7[[\"Purchase Price\", \"Age_BI\", \"Years of Warranty\"]]\n",
        "x_7_c_0_f = df_0_7[[\"Type_short\", \"Technology\", \"Probleem code\", \"Warranty\"]]          \n",
        "y_7 = df_0_7['ColorCode']\n",
        "df_0_7['y_0_7'] = np.where(y_7 == 7, 1, 0)\n",
        "y_0_7 = df_0_7['y_0_7']"
      ],
      "metadata": {
        "id": "-hq8nN7uNpFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot encoding of categorical values\n",
        "\n",
        "x_0_c_0 = pd.get_dummies(x_0_c_0_f)\n",
        "x_1_c_0 = pd.get_dummies(x_1_c_0_f)\n",
        "x_2_c_0 = pd.get_dummies(x_2_c_0_f)\n",
        "x_3_c_0 = pd.get_dummies(x_3_c_0_f)\n",
        "x_4_c_0 = pd.get_dummies(x_4_c_0_f)\n",
        "x_5_c_0 = pd.get_dummies(x_5_c_0_f)\n",
        "x_6_c_0 = pd.get_dummies(x_6_c_0_f)\n",
        "x_7_c_0 = pd.get_dummies(x_7_c_0_f)\n"
      ],
      "metadata": {
        "id": "23-xNuRuNpH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#minmax scaler for numerical values\n",
        "scaler = MinMaxScaler()\n",
        "x_0_s_0 = pd.DataFrame(scaler.fit_transform(x_0_n_0_f),columns=x_0_n_0_f.columns, index=x_0_n_0_f.index) \n",
        "x_1_s_0 = pd.DataFrame(scaler.fit_transform(x_1_n_0_f),columns=x_1_n_0_f.columns, index=x_1_n_0_f.index) \n",
        "x_2_s_0 = pd.DataFrame(scaler.fit_transform(x_2_n_0_f),columns=x_2_n_0_f.columns, index=x_2_n_0_f.index)\n",
        "x_3_s_0 = pd.DataFrame(scaler.fit_transform(x_3_n_0_f),columns=x_3_n_0_f.columns, index=x_3_n_0_f.index)\n",
        "x_4_s_0 = pd.DataFrame(scaler.fit_transform(x_4_n_0_f),columns=x_4_n_0_f.columns, index=x_4_n_0_f.index)\n",
        "x_5_s_0 = pd.DataFrame(scaler.fit_transform(x_5_n_0_f),columns=x_5_n_0_f.columns, index=x_5_n_0_f.index)\n",
        "x_6_s_0 = pd.DataFrame(scaler.fit_transform(x_6_n_0_f),columns=x_6_n_0_f.columns, index=x_6_n_0_f.index)\n",
        "x_7_s_0 = pd.DataFrame(scaler.fit_transform(x_7_n_0_f),columns=x_7_n_0_f.columns, index=x_7_n_0_f.index)\n"
      ],
      "metadata": {
        "id": "5mB0j7WKNpKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge two dataframes again\n",
        "x_0_0 = pd.concat([x_0_s_0, x_0_c_0], axis=1).reindex(x_0_s_0.index)\n",
        "x_0_1 = pd.concat([x_1_s_0, x_1_c_0], axis=1).reindex(x_1_s_0.index)\n",
        "x_0_2 = pd.concat([x_2_s_0, x_2_c_0], axis=1).reindex(x_2_s_0.index)\n",
        "x_0_3 = pd.concat([x_3_s_0, x_3_c_0], axis = 1).reindex(x_3_s_0.index)\n",
        "x_0_4 = pd.concat([x_4_s_0, x_4_c_0], axis=1).reindex(x_4_s_0.index)\n",
        "x_0_5 = pd.concat([x_5_s_0, x_5_c_0], axis=1).reindex(x_5_s_0.index)\n",
        "x_0_6 = pd.concat([x_6_s_0, x_6_c_0], axis=1).reindex(x_6_s_0.index)\n",
        "x_0_7 = pd.concat([x_7_s_0, x_7_c_0], axis=1).reindex(x_7_s_0.index)"
      ],
      "metadata": {
        "id": "74ceInS9NpMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "cYSFB3EZNpOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Only needed for multiclass WITH sampling. \n",
        "oversample = SMOTE()\n",
        "x_0_0, y_0_0 = oversample.fit_resample(x_0_0, y_0_0)\n",
        "\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_1, y_0_1 = oversample.fit_resample(x_0_1, y_0_1)\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_2, y_0_2 = oversample.fit_resample(x_0_2, y_0_2)\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_3, y_0_3 = oversample.fit_resample(x_0_3, y_0_3)\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_4, y_0_4 = oversample.fit_resample(x_0_4, y_0_4)\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_5, y_0_5 = oversample.fit_resample(x_0_5, y_0_5)\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_6, y_0_6 = oversample.fit_resample(x_0_6, y_0_6)\n",
        "\n",
        "oversample = SMOTE()\n",
        "x_0_7, y_0_7 = oversample.fit_resample(x_0_7, y_0_7)"
      ],
      "metadata": {
        "id": "YXkpNSADPrxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training set and test set -- # 80% training and 20% test\n",
        "X_train_0_0, X_test_0_0, y_train_0_0, y_test_0_0 = train_test_split(x_0_0, y_0_0, test_size=0.2, random_state = 42)\n",
        "X_train_1_0, X_test_1_0, y_train_1_0, y_test_1_0 = train_test_split(x_0_1, y_0_1, test_size=0.2, random_state = 42) \n",
        "X_train_2_0, X_test_2_0, y_train_2_0, y_test_2_0 = train_test_split(x_0_2, y_0_2, test_size=0.2, random_state = 42)\n",
        "X_train_3_0, X_test_3_0, y_train_3_0, y_test_3_0 = train_test_split(x_0_3, y_0_3, test_size=0.2, random_state = 42)\n",
        "X_train_4_0, X_test_4_0, y_train_4_0, y_test_4_0 = train_test_split(x_0_4, y_0_4, test_size=0.2, random_state = 42)\n",
        "X_train_5_0, X_test_5_0, y_train_5_0, y_test_5_0 = train_test_split(x_0_5, y_0_5, test_size=0.2, random_state = 42)\n",
        "X_train_6_0, X_test_6_0, y_train_6_0, y_test_6_0 = train_test_split(x_0_6, y_0_6, test_size=0.2, random_state = 42)\n",
        "X_train_7_0, X_test_7_0, y_train_7_0, y_test_7_0 = train_test_split(x_0_7, y_0_7, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "qbFEvY0eQIPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "\n",
        "clfmodel = LogisticRegression(random_state=0)\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_0_0, y_train_0_0)\n",
        "y_clf_0_0 = clfmodel.predict(X_test_0_0)\n",
        "end = time.time()\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_1_0, y_train_1_0)\n",
        "y_clf_1_0 = clfmodel.predict(X_test_1_0)\n",
        "end = time.time()\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_2_0, y_train_2_0)\n",
        "y_clf_2_0 = clfmodel.predict(X_test_2_0)\n",
        "end = time.time()\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_3_0, y_train_3_0)\n",
        "y_clf_3_0 = clfmodel.predict(X_test_3_0)\n",
        "end = time.time()\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_4_0, y_train_4_0)\n",
        "y_clf_4_0 = clfmodel.predict(X_test_4_0)\n",
        "end = time.time()\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_5_0, y_train_5_0)\n",
        "y_clf_5_0 = clfmodel.predict(X_test_5_0)\n",
        "end = time.time()\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_6_0, y_train_6_0)\n",
        "y_clf_6_0 = clfmodel.predict(X_test_6_0)\n",
        "end = time.time()\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "clfmodel.fit(X_train_7_0, y_train_7_0)\n",
        "y_clf_7_0 = clfmodel.predict(X_test_7_0)\n",
        "end = time.time()\n",
        "\n",
        "\n",
        "print(\"Accuracy of Logistic Regression for model 0 is : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_clf_0_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model 0 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_clf_0_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 0 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_clf_0_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 0 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_clf_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 0 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_clf_0_0)))\n",
        "print(\"MCC score for Logistic Regression for model 0 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0, y_clf_0_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_clf_1_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_clf_1_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 1 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_clf_1_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 1 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_clf_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_clf_1_0)))\n",
        "print(\"MCC score for Logistic Regression for model 0 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0, y_clf_1_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 2 is : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_clf_2_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model 2 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_clf_2_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 2 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_clf_2_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 2 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_clf_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 2 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_clf_2_0)))\n",
        "print(\"MCC score for Logistic Regression for model 2 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0, y_clf_2_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 3 is : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_clf_3_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_clf_3_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_clf_3_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_clf_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_clf_3_0)))\n",
        "print(\"MCC score for Logistic Regression for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0, y_clf_3_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 4 is : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_clf_4_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model 4 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_clf_4_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 4 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_clf_4_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 4 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_clf_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 4 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_clf_4_0)))\n",
        "print(\"MCC score for Logistic Regression for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0, y_clf_4_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 5 is : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_clf_5_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model  5 is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_clf_5_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 5 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_clf_5_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 5 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_clf_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 5 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_clf_5_0)))\n",
        "print(\"MCC score for Logistic Regression for model 5 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0, y_clf_5_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 6 is : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_clf_6_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model  6 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_clf_6_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_clf_6_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_clf_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_clf_6_0)))\n",
        "print(\"MCC score for Logistic Regression for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0, y_clf_6_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"////\")\n",
        "print(\"Accuracy of Logistic Regression for model 7 is : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_clf_7_0)))\n",
        "print(\"Weighted F1 score for Logistic Regression for model  7 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_clf_7_0, average='weighted')))\n",
        "print(\"Recall score for Logistic Regression for model 7 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_clf_7_0, average='weighted')))\n",
        "print(\"Precision score for Logistic Regression for model 7 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_clf_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Logistic Regression for model 7 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_clf_7_0)))\n",
        "print(\"MCC score for Logistic Regression for model 7 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0, y_clf_7_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')"
      ],
      "metadata": {
        "id": "OtpAmxB_QR1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_0_0, y_train_0_0)\n",
        "y_rf_0_0 =  rf_model.predict(X_test_0_0)\n",
        "print(\"Accuracy of rf for model 0 : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_rf_0_0)))\n",
        "print(\"Weighted F1 score for rf  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_rf_0_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_rf_0_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_rf_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_rf_0_0)))\n",
        "print(\"MCC score for rf  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0,y_rf_0_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "print(\"//\")\n",
        "\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_1_0, y_train_1_0)\n",
        "y_rf_1_0 =  rf_model.predict(X_test_1_0)\n",
        "print(\"Accuracy of rf for model 0 : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_rf_1_0)))\n",
        "print(\"Weighted F1 score for rf  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_rf_1_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_rf_1_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_rf_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_rf_1_0)))\n",
        "print(\"MCC score for rf  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0,y_rf_1_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "\n",
        "\n",
        "print(\"//\")\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_2_0, y_train_2_0)\n",
        "y_rf_2_0 =  rf_model.predict(X_test_2_0)\n",
        "print(\"Accuracy of rf for model 0 : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_rf_2_0)))\n",
        "print(\"Weighted F1 score for rf  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_rf_2_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_rf_2_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_rf_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_rf_2_0)))\n",
        "print(\"MCC score for rf  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0,y_rf_2_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_3_0, y_train_3_0)\n",
        "y_rf_3_0 =  rf_model.predict(X_test_3_0)\n",
        "print(\"Accuracy of rf for model 3 : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_rf_3_0)))\n",
        "print(\"Weighted F1 score for rf  for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_rf_3_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_rf_3_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_rf_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_rf_3_0)))\n",
        "print(\"MCC score for rf  for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0,y_rf_3_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "print(\"//\")\n",
        "\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_4_0, y_train_4_0)\n",
        "y_rf_4_0 =  rf_model.predict(X_test_4_0)\n",
        "print(\"Accuracy of rf for model 4 : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_rf_4_0)))\n",
        "print(\"Weighted F1 score for rf  for model 4 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_rf_4_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 4 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_rf_4_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 4 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_rf_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 4 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_rf_4_0)))\n",
        "print(\"MCC score for rf  for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0,y_rf_4_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "print(\"//\")\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_5_0, y_train_5_0)\n",
        "y_rf_5_0 =  rf_model.predict(X_test_5_0)\n",
        "print(\"Accuracy of rf for model 5 : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_rf_5_0)))\n",
        "print(\"Weighted F1 score for rf  for model 5 is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_rf_5_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 5 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_rf_5_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 5 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_rf_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 5 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_rf_5_0)))\n",
        "print(\"MCC score for rf  for model 5 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0,y_rf_5_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "print(\"//\")\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_6_0, y_train_6_0)\n",
        "y_rf_6_0 =  rf_model.predict(X_test_6_0)\n",
        "print(\"Accuracy of rf for model 6 : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_rf_6_0)))\n",
        "print(\"Weighted F1 score for rf  for model 6 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_rf_6_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_rf_6_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_rf_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_rf_6_0)))\n",
        "print(\"MCC score for rf  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0,y_rf_6_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n",
        "\n",
        "start = time.time()\n",
        "rf_model.fit(X_train_7_0, y_train_7_0)\n",
        "y_rf_7_0 =  rf_model.predict(X_test_7_0)\n",
        "print(\"Accuracy of rf for model 7 : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_rf_7_0)))\n",
        "print(\"Weighted F1 score for rf  for model 7 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_rf_7_0, average='weighted')))\n",
        "print(\"Recall score for rf  for model 7 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_rf_7_0, average='weighted')))\n",
        "print(\"Precision score for rf  for model 7 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_rf_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for rf  for model 7 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_rf_7_0)))\n",
        "print(\"MCC score for rf  for model 7 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0,y_rf_7_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n"
      ],
      "metadata": {
        "id": "8QLoJpCiRz14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross-validation for Logistic Regression\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True) \n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "#build multiple linear regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "#use LOOCV to evaluate model (x_0_3 & y_0_3 can be changed to check for other spare part)\n",
        "scores = cross_validate(model, x_0_3, y_0_3, scoring= scoring ,cv=cv, n_jobs=-1)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "LNc2XRB_RahT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svmmodel = svm.SVC()\n",
        "svmmodel.fit(X_train_0_0, y_train_0_0)\n",
        "y_svm_0_0 = svmmodel.predict(X_test_0_0)\n",
        "print(\"Accuracy of SVM for model 0 is : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_svm_0_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 0 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_svm_0_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 0 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_svm_0_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 0 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_svm_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM for model 0 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_svm_0_0)))\n",
        "print(\"MCC score for SVM for model 0 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0, y_svm_0_0)))\n",
        "\n",
        "start = time.time()\n",
        "svmmodel.fit(X_train_1_0, y_train_1_0)\n",
        "y_svm_1_0 = svmmodel.predict(X_test_1_0)\n",
        "print(\"Accuracy of SVM for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_svm_1_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_svm_1_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_svm_1_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_svm_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_svm_1_0)))\n",
        "print(\"MCC score for SVM for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0, y_svm_1_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "\n",
        "tart = time.time()\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "svmmodel.fit(X_train_2_0, y_train_2_0)\n",
        "y_svm_2_0 = svmmodel.predict(X_test_2_0)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"Accuracy of SVM for model 2 is : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_svm_2_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 2 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_svm_2_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 2 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_svm_2_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 2 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_svm_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_svm_2_0)))\n",
        "print(\"MCC score for SVM  for model 2 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0, y_svm_2_0)))\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "start = time.time()\n",
        "svmmodel.fit(X_train_3_0, y_train_3_0)\n",
        "y_svm_3_0 = svmmodel.predict(X_test_3_0)\n",
        "print(\"Accuracy of SVM for model 3 is : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_svm_3_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_svm_3_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_svm_3_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_svm_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM  for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_svm_3_0)))\n",
        "print(\"MCC score for SVM  for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0, y_svm_3_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "print(\"////\")\n",
        "\n",
        "start = time.time()\n",
        "svmmodel.fit(X_train_4_0, y_train_4_0)\n",
        "y_svm_4_0 = svmmodel.predict(X_test_4_0)\n",
        "print(\"Accuracy of SVM for model 4 is : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_svm_4_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 4 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_svm_4_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 4 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_svm_4_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 4 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_svm_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM  for model 4 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_svm_4_0)))\n",
        "print(\"MCC score for SVM  for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0, y_svm_4_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "print(\"////\")\n",
        "\n",
        "start = time.time()\n",
        "svmmodel.fit(X_train_5_0, y_train_5_0)\n",
        "y_svm_5_0 = svmmodel.predict(X_test_5_0)\n",
        "print(\"Accuracy of SVM for model 5 is : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_svm_5_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 5is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_svm_5_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 5 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_svm_5_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 5 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_svm_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM  for model 5 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_svm_5_0)))\n",
        "print(\"MCC score for SVM  for model 5 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0, y_svm_5_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "print(\"////\")\n",
        "\n",
        "start = time.time()\n",
        "svmmodel.fit(X_train_6_0, y_train_6_0)\n",
        "y_svm_6_0 = svmmodel.predict(X_test_6_0)\n",
        "print(\"Accuracy of SVM for model 6 is : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_svm_6_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 6 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_svm_6_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_svm_6_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_svm_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_svm_6_0)))\n",
        "print(\"MCC score for SVM  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0, y_svm_6_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "print(\"////\")\n",
        "\n",
        "start = time.time()\n",
        "svmmodel.fit(X_train_7_0, y_train_7_0)\n",
        "y_svm_7_0 = svmmodel.predict(X_test_7_0)\n",
        "print(\"Accuracy of SVM for model 7 is : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_svm_7_0)))\n",
        "print(\"Weighted F1 score for SVM  for model 7 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_svm_7_0, average='weighted')))\n",
        "print(\"Recall score for SVM  for model 7 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_svm_7_0, average='weighted')))\n",
        "print(\"Precision score for SVM  for model 7 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_svm_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for SVM for model 7 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_svm_7_0)))\n",
        "print(\"MCC score for SVM for model 7 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0, y_svm_7_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "print(\"////\")"
      ],
      "metadata": {
        "id": "O8TNGJq1R0YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_hastie_10_2\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "import shap\n",
        "# fit model no training data\n",
        "XGBmodel = XGBClassifier()\n",
        "\n",
        "XGBmodel.fit(X_train_0_0, y_train_0_0)\n",
        "y_xgb_0_0 = XGBmodel.predict(X_test_0_0)\n",
        "print(\"Accuracy of XGB for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_xgb_0_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_xgb_0_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_xgb_0_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_xgb_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_xgb_0_0)))\n",
        "print(\"MCC score for XGB for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0,y_xgb_0_0)))\n",
        "\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_0_0)\n",
        "shap.summary_plot(shap_values, X_test_0_0)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "XGBmodel.fit(X_train_1_0, y_train_1_0)\n",
        "y_xgb_1_0 = XGBmodel.predict(X_test_1_0)\n",
        "print(\"Accuracy of XGB for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_xgb_1_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_xgb_1_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_xgb_1_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_xgb_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_xgb_1_0)))\n",
        "print(\"MCC score for XGB for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0,y_xgb_1_0)))\n",
        "print(\"\")\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_1_0)\n",
        "shap.summary_plot(shap_values, X_test_1_0)\n",
        "\n",
        "\n",
        "# fit model no training data\n",
        "XGBmodel.fit(X_train_2_0, y_train_2_0)\n",
        "y_xgb_2_0 = XGBmodel.predict(X_test_2_0)\n",
        "print(\"Accuracy of XGB for model 2 is : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_xgb_2_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_xgb_2_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_xgb_2_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_xgb_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_xgb_2_0)))\n",
        "print(\"MCC score for XGB  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0,y_xgb_2_0)))\n",
        "print(\"\")\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_2_0)\n",
        "shap.summary_plot(shap_values, X_test_2_0)\n",
        "\n",
        "XGBmodel.fit(X_train_3_0, y_train_3_0)\n",
        "y_xgb_3_0 = XGBmodel.predict(X_test_3_0)\n",
        "print(\"Accuracy of XGB for model 3 is : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_xgb_3_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_xgb_3_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_xgb_3_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_xgb_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_xgb_3_0)))\n",
        "print(\"MCC score for XGB  for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0,y_xgb_3_0)))\n",
        "print(\"\")\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_3_0)\n",
        "shap.summary_plot(shap_values, X_test_3_0)\n",
        "\n",
        "\n",
        "XGBmodel.fit(X_train_4_0, y_train_4_0)\n",
        "y_xgb_4_0 = XGBmodel.predict(X_test_4_0)\n",
        "print(\"Accuracy of XGB for model 4 is : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_xgb_4_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 4 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_xgb_4_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 4 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_xgb_4_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 4 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_xgb_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 4 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_xgb_4_0)))\n",
        "print(\"MCC score for XGB VM  for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0,y_xgb_4_0)))\n",
        "print(\"\")\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_4_0)\n",
        "shap.summary_plot(shap_values, X_test_4_0)\n",
        "\n",
        "XGBmodel.fit(X_train_5_0, y_train_5_0)\n",
        "y_xgb_5_0 = XGBmodel.predict(X_test_5_0)\n",
        "print(\"Accuracy of XGB for model 5 is : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_xgb_5_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_xgb_5_0, average='weighted')))\n",
        "print(\"Recall score for XGB for model 6 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_xgb_5_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_xgb_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_xgb_5_0)))\n",
        "print(\"MCC score for XGB  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0,y_xgb_5_0)))\n",
        "print(\"\")\n",
        "\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_5_0)\n",
        "shap.summary_plot(shap_values, X_test_5_0)\n",
        "\n",
        "XGBmodel.fit(X_train_6_0, y_train_6_0)\n",
        "y_xgb_6_0 = XGBmodel.predict(X_test_6_0)\n",
        "print(\"Accuracy of XGB for model 6 is : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_xgb_6_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_xgb_6_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_xgb_6_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_xgb_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_xgb_6_0)))\n",
        "print(\"MCC score for XGB  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0,y_xgb_6_0)))\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_6_0)\n",
        "shap.summary_plot(shap_values, X_test_6_0)\n",
        "\n",
        "XGBmodel.fit(X_train_7_0, y_train_7_0)\n",
        "y_xgb_7_0 = XGBmodel.predict(X_test_7_0)\n",
        "print(\"Accuracy of XGB for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_xgb_7_0)))\n",
        "print(\"Weighted F1 score for XGB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_xgb_7_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_xgb_7_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_xgb_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_xgb_7_0)))\n",
        "print(\"MCC score for XGB for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0,y_xgb_7_0)))\n",
        "print(\"\")\n",
        "explainer = shap.TreeExplainer(XGBmodel)\n",
        "shap_values = explainer.shap_values(X_test_7_0)\n",
        "shap.summary_plot(shap_values, X_test_7_0)\n"
      ],
      "metadata": {
        "id": "1cju5G8CR0a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define cross-validation method to use\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True) \n",
        "\n",
        "scoring = ['accuracy', 'f1_weighted', 'precision_weighted', 'recall_weighted']\n",
        "\n",
        "#build multiple linear regression model\n",
        "model = XGBClassifier()\n",
        "\n",
        "#use LOOCV to evaluate model\n",
        "scores = cross_validate(model, x_0_0, x_0_0, scoring= scoring ,cv=cv, n_jobs=-1)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "IUuZPvoER0dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import neural_network, naive_bayes, neighbors, svm, ensemble\n",
        "\n",
        "\n",
        "dtmodel = DecisionTreeClassifier(criterion='entropy')\n",
        "dtmodel.fit(X_train_0_0, y_train_0_0)\n",
        "y_dt_0_0 = dtmodel.predict(X_test_0_0)\n",
        "\n",
        "dtmodel.fit(X_train_1_0, y_train_1_0)\n",
        "y_dt_1_0 = dtmodel.predict(X_test_1_0)\n",
        "\n",
        "dtmodel.fit(X_train_2_0, y_train_2_0)\n",
        "y_dt_2_0 = dtmodel.predict(X_test_2_0)\n",
        "\n",
        "dtmodel.fit(X_train_3_0, y_train_3_0)\n",
        "y_dt_3_0 = dtmodel.predict(X_test_3_0)\n",
        "\n",
        "dtmodel.fit(X_train_4_0, y_train_4_0)\n",
        "y_dt_4_0 = dtmodel.predict(X_test_4_0)\n",
        "\n",
        "dtmodel.fit(X_train_5_0, y_train_5_0)\n",
        "y_dt_5_0 = dtmodel.predict(X_test_5_0)\n",
        "\n",
        "dtmodel.fit(X_train_6_0, y_train_6_0)\n",
        "y_dt_6_0 = dtmodel.predict(X_test_6_0)\n",
        "\n",
        "dtmodel.fit(X_train_7_0, y_train_7_0)\n",
        "y_dt_7_0 = dtmodel.predict(X_test_7_0)\n",
        "\n",
        "print(\"Accuracy of DT for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_dt_0_0)))\n",
        "print(\"Weighted F1 score for DT for model 1 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_dt_0_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 1 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_dt_0_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 1 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_dt_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_dt_0_0)))\n",
        "print(\"MCC score for dt for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0,y_xgb_0_0)))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_dt_1_0)))\n",
        "print(\"Weighted F1 score for DT for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_dt_1_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 1 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_dt_1_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 1 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_dt_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_dt_1_0)))\n",
        "print(\"MCC score for dt for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0,y_xgb_1_0)))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 2 is : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_dt_2_0)))\n",
        "print(\"Weighted F1 score for DT for model 2 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_dt_2_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 2 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_dt_2_0, average='macro')))\n",
        "print(\"Precision score for Decision Tree for model 2 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_dt_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 2 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_dt_2_0)))\n",
        "print(\"MCC score for dt for model 2 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0,y_xgb_2_0)))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 3 is : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_dt_3_0)))\n",
        "print(\"Weighted F1 score for DT for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_dt_3_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_dt_3_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_dt_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_dt_3_0)))\n",
        "print(\"MCC score for dt for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0,y_xgb_3_0)))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 4 is : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_dt_4_0)))\n",
        "print(\"Weighted F1 score for DT for model 4 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_dt_4_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 4 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_dt_4_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 4 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_dt_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 4 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_dt_4_0)))\n",
        "print(\"MCC score for dt for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0,y_xgb_4_0)))\n",
        "print(\"MCC score for dt for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0,y_xgb_4_0))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 5 is : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_dt_5_0)))\n",
        "print(\"Weighted F1 score for DT for model 5 is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_dt_5_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 5 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_dt_5_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 5 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_dt_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 5 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_dt_5_0)))\n",
        "print(\"MCC score for dt for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0,y_xgb_5_0)))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 6 is : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_dt_6_0)))\n",
        "print(\"Weighted F1 score for DT for model 6 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_dt_6_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_dt_6_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_dt_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_dt_6_0)))\n",
        "print(\"MCC score for dt for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0,y_xgb_6_0)))\n",
        "print()\n",
        "print(\"Accuracy of DT for model 7 is : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_dt_7_0)))\n",
        "print(\"Weighted F1 score for DT for model 7 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_dt_7_0, average='weighted')))\n",
        "print(\"Recall score for Decision Tree for model 7 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_dt_7_0, average='micro')))\n",
        "print(\"Precision score for Decision Tree for model 7 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_dt_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for Decision Tree for model 7 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_dt_7_0)))\n",
        "print(\"MCC score for dt for model 7 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0,y_xgb_7_0)))\n",
        "print()\n"
      ],
      "metadata": {
        "id": "QsF6cVENT7fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 6)\n",
        "knn.fit(X_train_0_0, y_train_0_0)\n",
        "y_knn_0_0 = knn.predict(X_test_0_0)\n",
        "start = time.time()\n",
        "print(\"Accuracy of XGB for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_knn_0_0)))\n",
        "print(\"Weighted F1 score for GB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_knn_0_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_knn_0_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_knn_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_knn_0_0)))\n",
        "print(\"MCC score for XGB  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0,y_knn_0_0)))\n",
        "\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "knn.fit(X_train_1_0, y_train_1_0)\n",
        "y_knn_1_0 = knn.predict(X_test_1_0)\n",
        "print(\"Accuracy of XGB for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_knn_1_0)))\n",
        "print(\"Weighted F1 score for GB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_knn_1_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_knn_1_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_knn_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_knn_1_0)))\n",
        "print(\"MCC score for XGB  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0,y_knn_1_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "\n",
        "start = time.time()\n",
        "knn.fit(X_train_2_0, y_train_2_0)\n",
        "y_knn_2_0 = knn.predict(X_test_2_0)\n",
        "\n",
        "print(\"Accuracy of XGB for model 1 is : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_knn_2_0)))\n",
        "print(\"Weighted F1 score for GB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_knn_2_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_knn_2_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_knn_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_knn_2_0)))\n",
        "print(\"MCC score for XGB  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0,y_knn_2_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "\n",
        "start = time.time()\n",
        "knn.fit(X_train_3_0, y_train_3_0)\n",
        "y_knn_3_0 = knn.predict(X_test_3_0)\n",
        "print(\"Accuracy of XGB for model 3 is : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_knn_3_0)))\n",
        "print(\"Weighted F1 score for GB  for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_knn_3_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_knn_3_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_knn_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_knn_3_0)))\n",
        "print(\"MCC score for XGB  for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0,y_knn_3_0)))\n",
        "print(\"\")\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "start = time.time()\n",
        "knn.fit(X_train_4_0, y_train_4_0)\n",
        "y_knn_4_0 = knn.predict(X_test_4_0)\n",
        "print(\"Accuracy of XGB for model 4 is : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_knn_4_0)))\n",
        "print(\"Weighted F1 score for GB  for model 4 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_knn_4_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 4 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_knn_4_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 4 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_knn_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 4 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_knn_4_0)))\n",
        "print(\"MCC score for XGB  for model 4 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0,y_knn_4_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "\n",
        "knn.fit(X_train_5_0, y_train_5_0)\n",
        "y_knn_5_0 = knn.predict(X_test_5_0)\n",
        "print(\"Accuracy of KNN for model 5 is : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_knn_5_0)))\n",
        "print(\"Weighted F1 score for KNN  for model 5 is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_knn_5_0, average='weighted')))\n",
        "print(\"Recall score for KNN  for model 5 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_knn_5_0, average='weighted')))\n",
        "print(\"Precision score for KNN  for model 5 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_knn_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for KNN  for model 5 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_knn_5_0)))\n",
        "print(\"MCC score for KNN  for model 5 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0,y_knn_5_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "\n",
        "start = time.time()\n",
        "knn.fit(X_train_6_0, y_train_6_0)\n",
        "y_knn_6_0 = knn.predict(X_test_6_0)\n",
        "print(\"Accuracy of KNN for model 6 is : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_knn_6_0)))\n",
        "print(\"Weighted F1 score for KNN  for model 6 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_knn_6_0, average='weighted')))\n",
        "print(\"Recall score for KNN  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_knn_6_0, average='weighted')))\n",
        "print(\"Precision score for KNN  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_knn_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for KNN  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_knn_6_0)))\n",
        "print(\"MCC score for KNN  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0,y_knn_6_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")\n",
        "\n",
        "start = time.time()\n",
        "knn.fit(X_train_7_0, y_train_7_0)\n",
        "y_knn_7_0 = knn.predict(X_test_7_0)\n",
        "print(\"Accuracy of KNN for model 7 is : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_knn_7_0)))\n",
        "print(\"Weighted F1 score for KNN  for model 7 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_knn_7_0, average='weighted')))\n",
        "print(\"Recall score for KNN  for model 7 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_knn_7_0, average='weighted')))\n",
        "print(\"Precision score for KNN  for model 7 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_knn_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for KNN  for model 7 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_knn_7_0)))\n",
        "print(\"MCC score for KNN  for model 7 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0,y_knn_7_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "CGdeVJWhRSpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural Networks \n",
        "nn_model = neural_network.MLPClassifier(hidden_layer_sizes=(30,15,1), activation = 'relu', solver = 'adam')\n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_0_0, y_train_0_0)\n",
        "y_nn_0_0 =nn_model.predict(X_test_0_0)\n",
        "print(\"Accuracy of NN for model 0 : {0:0.4f}\" . format(accuracy_score(y_test_0_0, y_nn_0_0)))\n",
        "print(\"Weighted F1 score for GB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_0_0, y_nn_0_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_0_0, y_nn_0_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_0_0, y_nn_0_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_0_0, y_nn_0_0)))\n",
        "print(\"MCC score for XGB  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_0_0,y_nn_0_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_1_0, y_train_1_0)\n",
        "y_nn_1_0 =nn_model.predict(X_test_1_0)\n",
        "print(\"Accuracy of NN for model 1 : {0:0.4f}\" . format(accuracy_score(y_test_1_0, y_nn_1_0)))\n",
        "print(\"Weighted F1 score for GB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_1_0, y_nn_1_0, average='weighted')))\n",
        "print(\"Recall score for XGB  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_1_0, y_nn_1_0, average='weighted')))\n",
        "print(\"Precision score for XGB  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_1_0, y_nn_1_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for XGB  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_1_0, y_nn_1_0)))\n",
        "print(\"MCC score for XGB  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_1_0,y_nn_1_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "\n",
        "\n",
        "start = time.time() \n",
        "\n",
        "nn_model.fit(X_train_2_0, y_train_2_0)\n",
        "y_nn_2_0 = nn_model.predict(X_test_2_0)\n",
        "print(\"Accuracy of NN for model 2 : {0:0.4f}\" . format(accuracy_score(y_test_2_0, y_nn_2_0)))\n",
        "print(\"Weighted F1 score for GB  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_2_0, y_nn_2_0, average='weighted')))\n",
        "print(\"Recall score for NN  for model 2 is : {0:0.4f}\" .format(recall_score(y_test_2_0, y_nn_2_0, average='weighted')))\n",
        "print(\"Precision score for NN  for model 2 is : {0:0.4f}\" .format(precision_score(y_test_2_0, y_nn_2_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for NN  for model 2 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_2_0, y_nn_2_0)))\n",
        "print(\"MCC score for NN  for model 2 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_2_0,y_nn_2_0)))\n",
        "\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_3_0, y_train_3_0)\n",
        "y_nn_3_0 =nn_model.predict(X_test_3_0)\n",
        "print(\"Accuracy of NN for model 3 : {0:0.4f}\" . format(accuracy_score(y_test_3_0, y_nn_3_0)))\n",
        "print(\"Weighted NN score for GB  for model 3 is : {0:0.4f}\" .format(f1_score(y_test_3_0, y_nn_3_0, average='weighted')))\n",
        "print(\"Recall score for NN  for model 3 is : {0:0.4f}\" .format(recall_score(y_test_3_0, y_nn_3_0, average='weighted')))\n",
        "print(\"Precision score for NN  for model 3 is : {0:0.4f}\" .format(precision_score(y_test_3_0, y_nn_3_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for NN  for model 3 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_3_0, y_nn_3_0)))\n",
        "print(\"MCC score for NN  for model 3 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_3_0,y_nn_3_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_4_0, y_train_4_0)\n",
        "y_nn_4_0 =nn_model.predict(X_test_4_0)\n",
        "print(\"Accuracy of NN for model 4 : {0:0.4f}\" . format(accuracy_score(y_test_4_0, y_nn_4_0)))\n",
        "print(\"Weighted F1 score for NN  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_4_0, y_nn_4_0, average='weighted')))\n",
        "print(\"Recall score for NN  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_4_0, y_nn_4_0, average='weighted')))\n",
        "print(\"Precision score for NN  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_4_0, y_nn_4_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for NN  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_4_0, y_nn_4_0)))\n",
        "print(\"MCC score for NN  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_4_0,y_nn_4_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_5_0, y_train_5_0)\n",
        "y_nn_5_0 = nn_model.predict(X_test_5_0)\n",
        "print(\"Accuracy of NN for model 5 : {0:0.4f}\" . format(accuracy_score(y_test_5_0, y_nn_5_0)))\n",
        "print(\"Weighted F1 score for NN  for model 1 is : {0:0.4f}\" .format(f1_score(y_test_5_0, y_nn_5_0, average='weighted')))\n",
        "print(\"Recall score for NN  for model 1 is : {0:0.4f}\" .format(recall_score(y_test_5_0, y_nn_5_0, average='weighted')))\n",
        "print(\"Precision score for NN  for model 1 is : {0:0.4f}\" .format(precision_score(y_test_5_0, y_nn_5_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for NN  for model 1 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_5_0, y_nn_5_0)))\n",
        "print(\"MCC score for NN  for model 1 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_5_0,y_nn_5_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')          \n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_6_0, y_train_6_0)\n",
        "y_nn_6_0 = nn_model.predict(X_test_6_0)\n",
        "print(\"Accuracy of NN for model 6 : {0:0.4f}\" . format(accuracy_score(y_test_6_0, y_nn_6_0)))\n",
        "print(\"Weighted F1 score for NN  for model 6 is : {0:0.4f}\" .format(f1_score(y_test_6_0, y_nn_6_0, average='weighted')))\n",
        "print(\"Recall score for NN  for model 6 is : {0:0.4f}\" .format(recall_score(y_test_6_0, y_nn_6_0, average='weighted')))\n",
        "print(\"Precision score for NN  for model 6 is : {0:0.4f}\" .format(precision_score(y_test_6_0, y_nn_6_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for NN  for model 6 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_6_0, y_nn_6_0)))\n",
        "print(\"MCC score for NN  for model 6 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_6_0,y_nn_6_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "             \n",
        "\n",
        "start = time.time()\n",
        "nn_model.fit(X_train_7_0, y_train_7_0)\n",
        "y_nn_7_0 = nn_model.predict(X_test_7_0)\n",
        "print(\"Accuracy of NN for model 7 : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_nn_7_0)))\n",
        "print(\"Accuracy of NN for model 7 : {0:0.4f}\" . format(accuracy_score(y_test_7_0, y_nn_7_0)))\n",
        "print(\"Weighted F1 score of NN for model 7   for model 1 is : {0:0.4f}\" .format(f1_score(y_test_7_0, y_nn_7_0, average='weighted')))\n",
        "print(\"Recall score for NN  for model 7 is : {0:0.4f}\" .format(recall_score(y_test_7_0, y_nn_7_0, average='weighted')))\n",
        "print(\"Precision score for NN  for model 7 is : {0:0.4f}\" .format(precision_score(y_test_7_0, y_nn_7_0, average='weighted')))\n",
        "print(\"Cohen Kappa score for NN  for model 7 is : {0:0.4f}\" .format(cohen_kappa_score(y_test_7_0, y_nn_7_0)))\n",
        "print(\"MCC score for NN  for model 7 is : {0:0.4f}\" .format(matthews_corrcoef(y_test_7_0,y_nn_7_0)))\n",
        "end = time.time()\n",
        "print('Time of loading file is : ', (end - start)/60, 'minutes')         \n",
        "\n"
      ],
      "metadata": {
        "id": "JeCXENcv37gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zfUMNAxd37jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jf5gK8Jf37lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yv6nqQnk37nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u2-SrIh437qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QxR-VtK8T7xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N-oSIZ1IT7z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drawing of ROC curve\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "#set up plotting area\n",
        "plt.figure(0).clf()\n",
        "\n",
        "#fit logistic regression model and plot ROC curve\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_0_0, y_train_0_0)\n",
        "y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
        "\n",
        "#fit gradient boosted model and plot ROC curve\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train_0_0, y_train_0_0)\n",
        "y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "plt.plot(fpr,tpr,label=\"Gradient Boosting, AUC=\"+str(auc))\n",
        "\n",
        "#fit gradient boosted model and plot ROC curve\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train_0_0, y_train_0_0)\n",
        "y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "plt.plot(fpr,tpr,label=\"DT, AUC=\"+str(auc))\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_0_0, y_train_0_0)\n",
        "y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "plt.plot(fpr,tpr,label=\"RF, AUC=\"+str(auc))\n",
        "\n",
        "model = neural_network.MLPClassifier()\n",
        "model.fit(X_train_0_0, y_train_0_0)\n",
        "y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "plt.plot(fpr,tpr,label=\"MLP, AUC=\"+str(auc))\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors = 6)\n",
        "model.fit(X_train_0_0, y_train_0_0)\n",
        "y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "plt.plot(fpr,tpr,label=\"KNN, AUC=\"+str(auc))\n",
        "\n",
        "#model = svm.SVC()\n",
        "#model.fit(X_train_0_0, y_train_0_0)\n",
        "#y_pred = model.predict_proba(X_test_0_0)[:, 1]\n",
        "#fpr, tpr, _ = metrics.roc_curve(y_test_0_0, y_pred)\n",
        "#auc = round(metrics.roc_auc_score(y_test_0_0, y_pred), 4)\n",
        "#plt.plot(fpr,tpr,label=\"SVM, AUC=\"+str(auc))\n",
        "\n",
        "image_name = \"AUC0.png\"\n",
        "image_format = \"png\"\n",
        "plt.legend()\n",
        "plt.title('AUC curve for ColorCode0')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.savefig(image_name, format=image_format, dpi= 800)\n"
      ],
      "metadata": {
        "id": "4JnGZMf5T72c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}